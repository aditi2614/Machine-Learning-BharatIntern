{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164b0834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.73766273]\n",
      " [-0.73766273  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df=pd.read_csv('housing3.csv')\n",
    "x=df['LSTAT']\n",
    "y=df['MEDV']\n",
    "x=x.to_numpy()\n",
    "r=np.corrcoef(x,y)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7506b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTAT coff =  [[ 1.         -0.73766273]\n",
      " [-0.73766273  1.        ]]\n",
      "LSTAT coff =  [[1.         0.36044534]\n",
      " [0.36044534 1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.48372516]\n",
      " [-0.48372516  1.        ]]\n",
      "LSTAT coff =  [[1.         0.17526018]\n",
      " [0.17526018 1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.38830461]\n",
      " [-0.38830461  1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.42732077]\n",
      " [-0.42732077  1.        ]]\n",
      "LSTAT coff =  [[1.         0.69535995]\n",
      " [0.69535995 1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.37695457]\n",
      " [-0.37695457  1.        ]]\n",
      "LSTAT coff =  [[1.         0.24992873]\n",
      " [0.24992873 1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.38162623]\n",
      " [-0.38162623  1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.46853593]\n",
      " [-0.46853593  1.        ]]\n",
      "LSTAT coff =  [[ 1.         -0.50778669]\n",
      " [-0.50778669  1.        ]]\n",
      "LSTAT coff =  [[1.         0.33346082]\n",
      " [0.33346082 1.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 4.98  9.14  4.03  2.94  5.33  5.21 12.43 19.15 29.93 17.1  20.45 13.27\n 15.71  8.26 10.26  8.47  6.58 14.67 11.69 11.28 21.02 13.83 18.72 19.88\n 16.3  16.51 14.81 17.28 12.8  11.98 22.6  13.04 27.71 18.35 20.34  9.68\n 11.41  8.77 10.13  4.32  1.98  4.84  5.81  7.44  9.55 10.21 14.15 18.8\n 30.81 16.2  13.45  9.43  5.28  8.43 14.8   4.81  5.77  3.95  6.86  9.22\n 13.15 14.44  6.73  9.5   8.05  4.67 10.24  8.1  13.09  8.79  6.72  9.88\n  5.52  7.54  6.78  8.94 11.97 10.27 12.34  9.1   5.29  7.22  6.72  7.51\n  9.62  6.53 12.86  8.44  5.5   5.7   8.81  8.2   8.16  6.21 10.59  6.65\n 11.34  4.21  3.57  6.19  9.42  7.67 10.63 13.44 12.33 16.47 18.66 14.09\n 12.27 15.55 13.   10.16 16.21 17.09 10.45 15.76 12.04 10.3  15.37 13.61\n 14.37 14.27 17.93 25.41 17.58 14.81 27.26 17.19 15.39 18.34 12.6  12.26\n 11.12 15.03 17.31 16.96 16.9  14.59 21.32 18.46 24.16 34.41 26.82 26.42\n 29.29 27.8  16.65 29.53 28.32 21.45 14.1  13.28 12.12 15.79 15.12 15.02\n 16.14  4.59  6.43  7.39  5.5   1.73  1.92  3.32 11.64  9.81  3.7  12.14\n 11.1  11.32 14.43 12.03 14.69  9.04  9.64  5.33 10.11  6.29  6.92  5.04\n  7.56  9.45  4.82  5.68 13.98 13.15  4.45  6.68  4.56  5.39  5.1   4.69\n  2.87  5.03  4.38  2.97  4.08  8.61  6.62  4.56  4.45  7.43  3.11  3.81\n  2.88 10.87 10.97 18.06 14.66 23.09 17.27 23.98 16.03  9.38 29.55  9.47\n 13.51  9.69 17.92 10.5   9.71 21.46  9.93  7.6   4.14  4.63  3.13  6.36\n  3.92  3.76 11.65  5.25  2.47  3.95  8.05 10.88  9.54  4.73  6.36  7.37\n 11.38 12.4  11.22  5.19 12.5  18.46  9.16 10.15  9.52  6.56  5.9   3.59\n  3.53  3.54  6.57  9.25  3.11  5.12  7.79  6.9   9.59  7.26  5.91 11.25\n  8.1  10.45 14.79  7.44  3.16 13.65 13.    6.59  7.73  6.58  3.53  2.98\n  6.05  4.16  7.19  4.85  3.76  4.59  3.01  3.16  7.85  8.23 12.93  7.14\n  7.6   9.51  3.33  3.56  4.7   8.58 10.4   6.27  7.39 15.84  4.97  4.74\n  6.07  9.5   8.67  4.86  6.93  8.93  6.47  7.53  4.54  9.97 12.64  5.98\n 11.72  7.9   9.28 11.5  18.33 15.94 10.36 12.73  7.2   6.87  7.7  11.74\n  6.12  5.08  6.15 12.79  9.97  7.34  9.09 12.43  7.83  5.68  6.75  8.01\n  9.8  10.56  8.51  9.74  9.29  5.49  8.65  7.18  4.61 10.53 12.67  6.36\n  5.99  5.89  5.98  5.49  7.79  4.5   8.05  5.57 17.6  13.27 11.48 12.67\n  7.79 14.19 10.19 14.64  5.29  7.12 14.   13.33  3.26  3.73  2.96  9.53\n  8.88 34.77 37.97 13.44 23.24 21.24 23.69 21.78 17.21 21.08 23.6  24.56\n 30.63 30.81 28.28 31.99 30.62 20.85 17.11 18.76 25.68 15.17 16.35 17.12\n 19.37 19.92 30.59 29.97 26.77 20.32 20.31 19.77 27.38 22.98 23.34 12.13\n 26.4  19.78 10.11 21.22 34.37 20.08 36.98 29.05 25.79 26.64 20.62 22.74\n 15.02 15.7  14.1  23.29 17.16 24.39 15.69 14.52 21.52 24.08 17.64 19.69\n 12.03 16.22 15.17 23.27 18.05 26.45 34.02 22.88 22.11 19.52 16.59 18.85\n 23.79 23.98 17.79 16.44 18.13 19.31 17.44 17.73 17.27 16.74 18.71 18.13\n 19.01 16.94 16.23 14.7  16.42 14.65 13.99 10.29 13.22 14.13 17.15 21.32\n 18.13 14.76 16.29 12.87 14.36 11.66 18.14 24.1  18.68 24.91 18.03 13.11\n 10.74  7.74  7.01 10.42 13.34 10.58 14.98 11.45 18.06 23.97 29.68 18.07\n 13.35 12.01 13.59 17.6  21.14 14.1  12.92 15.1  14.33  9.67  9.08  5.64\n  6.48  7.88].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10932\\1471488240.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mregression_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m#Fit the data(train the model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mregression_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;31m#predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregression_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 4.98  9.14  4.03  2.94  5.33  5.21 12.43 19.15 29.93 17.1  20.45 13.27\n 15.71  8.26 10.26  8.47  6.58 14.67 11.69 11.28 21.02 13.83 18.72 19.88\n 16.3  16.51 14.81 17.28 12.8  11.98 22.6  13.04 27.71 18.35 20.34  9.68\n 11.41  8.77 10.13  4.32  1.98  4.84  5.81  7.44  9.55 10.21 14.15 18.8\n 30.81 16.2  13.45  9.43  5.28  8.43 14.8   4.81  5.77  3.95  6.86  9.22\n 13.15 14.44  6.73  9.5   8.05  4.67 10.24  8.1  13.09  8.79  6.72  9.88\n  5.52  7.54  6.78  8.94 11.97 10.27 12.34  9.1   5.29  7.22  6.72  7.51\n  9.62  6.53 12.86  8.44  5.5   5.7   8.81  8.2   8.16  6.21 10.59  6.65\n 11.34  4.21  3.57  6.19  9.42  7.67 10.63 13.44 12.33 16.47 18.66 14.09\n 12.27 15.55 13.   10.16 16.21 17.09 10.45 15.76 12.04 10.3  15.37 13.61\n 14.37 14.27 17.93 25.41 17.58 14.81 27.26 17.19 15.39 18.34 12.6  12.26\n 11.12 15.03 17.31 16.96 16.9  14.59 21.32 18.46 24.16 34.41 26.82 26.42\n 29.29 27.8  16.65 29.53 28.32 21.45 14.1  13.28 12.12 15.79 15.12 15.02\n 16.14  4.59  6.43  7.39  5.5   1.73  1.92  3.32 11.64  9.81  3.7  12.14\n 11.1  11.32 14.43 12.03 14.69  9.04  9.64  5.33 10.11  6.29  6.92  5.04\n  7.56  9.45  4.82  5.68 13.98 13.15  4.45  6.68  4.56  5.39  5.1   4.69\n  2.87  5.03  4.38  2.97  4.08  8.61  6.62  4.56  4.45  7.43  3.11  3.81\n  2.88 10.87 10.97 18.06 14.66 23.09 17.27 23.98 16.03  9.38 29.55  9.47\n 13.51  9.69 17.92 10.5   9.71 21.46  9.93  7.6   4.14  4.63  3.13  6.36\n  3.92  3.76 11.65  5.25  2.47  3.95  8.05 10.88  9.54  4.73  6.36  7.37\n 11.38 12.4  11.22  5.19 12.5  18.46  9.16 10.15  9.52  6.56  5.9   3.59\n  3.53  3.54  6.57  9.25  3.11  5.12  7.79  6.9   9.59  7.26  5.91 11.25\n  8.1  10.45 14.79  7.44  3.16 13.65 13.    6.59  7.73  6.58  3.53  2.98\n  6.05  4.16  7.19  4.85  3.76  4.59  3.01  3.16  7.85  8.23 12.93  7.14\n  7.6   9.51  3.33  3.56  4.7   8.58 10.4   6.27  7.39 15.84  4.97  4.74\n  6.07  9.5   8.67  4.86  6.93  8.93  6.47  7.53  4.54  9.97 12.64  5.98\n 11.72  7.9   9.28 11.5  18.33 15.94 10.36 12.73  7.2   6.87  7.7  11.74\n  6.12  5.08  6.15 12.79  9.97  7.34  9.09 12.43  7.83  5.68  6.75  8.01\n  9.8  10.56  8.51  9.74  9.29  5.49  8.65  7.18  4.61 10.53 12.67  6.36\n  5.99  5.89  5.98  5.49  7.79  4.5   8.05  5.57 17.6  13.27 11.48 12.67\n  7.79 14.19 10.19 14.64  5.29  7.12 14.   13.33  3.26  3.73  2.96  9.53\n  8.88 34.77 37.97 13.44 23.24 21.24 23.69 21.78 17.21 21.08 23.6  24.56\n 30.63 30.81 28.28 31.99 30.62 20.85 17.11 18.76 25.68 15.17 16.35 17.12\n 19.37 19.92 30.59 29.97 26.77 20.32 20.31 19.77 27.38 22.98 23.34 12.13\n 26.4  19.78 10.11 21.22 34.37 20.08 36.98 29.05 25.79 26.64 20.62 22.74\n 15.02 15.7  14.1  23.29 17.16 24.39 15.69 14.52 21.52 24.08 17.64 19.69\n 12.03 16.22 15.17 23.27 18.05 26.45 34.02 22.88 22.11 19.52 16.59 18.85\n 23.79 23.98 17.79 16.44 18.13 19.31 17.44 17.73 17.27 16.74 18.71 18.13\n 19.01 16.94 16.23 14.7  16.42 14.65 13.99 10.29 13.22 14.13 17.15 21.32\n 18.13 14.76 16.29 12.87 14.36 11.66 18.14 24.1  18.68 24.91 18.03 13.11\n 10.74  7.74  7.01 10.42 13.34 10.58 14.98 11.45 18.06 23.97 29.68 18.07\n 13.35 12.01 13.59 17.6  21.14 14.1  12.92 15.1  14.33  9.67  9.08  5.64\n  6.48  7.88].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df=pd.read_csv('housing3.csv')\n",
    "y=df['MEDV']\n",
    "x1=df['LSTAT']\n",
    "x2=df['ZN']\n",
    "x3=df['INDUS']\n",
    "x4=df['CHAS']\n",
    "x5=df['CRIM']\n",
    "x6=df['NOX']\n",
    "x7=df['RM']\n",
    "x8=df['AGE']\n",
    "x9=df['DIS']\n",
    "x10=df['RAD']\n",
    "x11=df['TAX']\n",
    "x12=df['PTRATIO']\n",
    "x13=df['B']\n",
    "r1=np.corrcoef(x1,y)\n",
    "r2=np.corrcoef(x2,y)\n",
    "r3=np.corrcoef(x3,y)\n",
    "r4=np.corrcoef(x4,y)\n",
    "r5=np.corrcoef(x5,y)\n",
    "r6=np.corrcoef(x6,y)\n",
    "r7=np.corrcoef(x7,y)\n",
    "r8=np.corrcoef(x8,y)\n",
    "r9=np.corrcoef(x9,y)\n",
    "r10=np.corrcoef(x10,y)\n",
    "r11=np.corrcoef(x11,y)\n",
    "r12=np.corrcoef(x12,y)\n",
    "r13=np.corrcoef(x13,y)\n",
    "print(\"LSTAT coff = \",r1)\n",
    "print(\"LSTAT coff = \",r2)\n",
    "print(\"LSTAT coff = \",r3)\n",
    "print(\"LSTAT coff = \",r4)\n",
    "print(\"LSTAT coff = \",r5)\n",
    "print(\"LSTAT coff = \",r6)\n",
    "print(\"LSTAT coff = \",r7)\n",
    "print(\"LSTAT coff = \",r8)\n",
    "print(\"LSTAT coff = \",r9)\n",
    "print(\"LSTAT coff = \",r10)\n",
    "print(\"LSTAT coff = \",r11)\n",
    "print(\"LSTAT coff = \",r12)\n",
    "print(\"LSTAT coff = \",r13)\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "#Fit the data(train the model)\n",
    "regression_model.fit(x, y)\n",
    "#predict\n",
    "y_predicted = regression_model.predict(x)\n",
    "print(y_predicted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9351fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0      18.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "501     0.0\n",
      "502     0.0\n",
      "503     0.0\n",
      "504     0.0\n",
      "505     0.0\n",
      "Name: ZN, Length: 506, dtype: float64], [0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "501    0\n",
      "502    0\n",
      "503    0\n",
      "504    0\n",
      "505    0\n",
      "Name: CHAS, Length: 506, dtype: int64], [0      6.575\n",
      "1      6.421\n",
      "2      7.185\n",
      "3      6.998\n",
      "4      7.147\n",
      "       ...  \n",
      "501    6.593\n",
      "502    6.120\n",
      "503    6.976\n",
      "504    6.794\n",
      "505    6.030\n",
      "Name: RM, Length: 506, dtype: float64], [0      4.0900\n",
      "1      4.9671\n",
      "2      4.9671\n",
      "3      6.0622\n",
      "4      6.0622\n",
      "        ...  \n",
      "501    2.4786\n",
      "502    2.2875\n",
      "503    2.1675\n",
      "504    2.3889\n",
      "505    2.5050\n",
      "Name: DIS, Length: 506, dtype: float64], [0      396.90\n",
      "1      396.90\n",
      "2      392.83\n",
      "3      394.63\n",
      "4      396.90\n",
      "        ...  \n",
      "501    391.99\n",
      "502    396.90\n",
      "503    396.90\n",
      "504    393.45\n",
      "505    396.90\n",
      "Name: B, Length: 506, dtype: float64]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 4.98  9.14  4.03  2.94  5.33  5.21 12.43 19.15 29.93 17.1  20.45 13.27\n 15.71  8.26 10.26  8.47  6.58 14.67 11.69 11.28 21.02 13.83 18.72 19.88\n 16.3  16.51 14.81 17.28 12.8  11.98 22.6  13.04 27.71 18.35 20.34  9.68\n 11.41  8.77 10.13  4.32  1.98  4.84  5.81  7.44  9.55 10.21 14.15 18.8\n 30.81 16.2  13.45  9.43  5.28  8.43 14.8   4.81  5.77  3.95  6.86  9.22\n 13.15 14.44  6.73  9.5   8.05  4.67 10.24  8.1  13.09  8.79  6.72  9.88\n  5.52  7.54  6.78  8.94 11.97 10.27 12.34  9.1   5.29  7.22  6.72  7.51\n  9.62  6.53 12.86  8.44  5.5   5.7   8.81  8.2   8.16  6.21 10.59  6.65\n 11.34  4.21  3.57  6.19  9.42  7.67 10.63 13.44 12.33 16.47 18.66 14.09\n 12.27 15.55 13.   10.16 16.21 17.09 10.45 15.76 12.04 10.3  15.37 13.61\n 14.37 14.27 17.93 25.41 17.58 14.81 27.26 17.19 15.39 18.34 12.6  12.26\n 11.12 15.03 17.31 16.96 16.9  14.59 21.32 18.46 24.16 34.41 26.82 26.42\n 29.29 27.8  16.65 29.53 28.32 21.45 14.1  13.28 12.12 15.79 15.12 15.02\n 16.14  4.59  6.43  7.39  5.5   1.73  1.92  3.32 11.64  9.81  3.7  12.14\n 11.1  11.32 14.43 12.03 14.69  9.04  9.64  5.33 10.11  6.29  6.92  5.04\n  7.56  9.45  4.82  5.68 13.98 13.15  4.45  6.68  4.56  5.39  5.1   4.69\n  2.87  5.03  4.38  2.97  4.08  8.61  6.62  4.56  4.45  7.43  3.11  3.81\n  2.88 10.87 10.97 18.06 14.66 23.09 17.27 23.98 16.03  9.38 29.55  9.47\n 13.51  9.69 17.92 10.5   9.71 21.46  9.93  7.6   4.14  4.63  3.13  6.36\n  3.92  3.76 11.65  5.25  2.47  3.95  8.05 10.88  9.54  4.73  6.36  7.37\n 11.38 12.4  11.22  5.19 12.5  18.46  9.16 10.15  9.52  6.56  5.9   3.59\n  3.53  3.54  6.57  9.25  3.11  5.12  7.79  6.9   9.59  7.26  5.91 11.25\n  8.1  10.45 14.79  7.44  3.16 13.65 13.    6.59  7.73  6.58  3.53  2.98\n  6.05  4.16  7.19  4.85  3.76  4.59  3.01  3.16  7.85  8.23 12.93  7.14\n  7.6   9.51  3.33  3.56  4.7   8.58 10.4   6.27  7.39 15.84  4.97  4.74\n  6.07  9.5   8.67  4.86  6.93  8.93  6.47  7.53  4.54  9.97 12.64  5.98\n 11.72  7.9   9.28 11.5  18.33 15.94 10.36 12.73  7.2   6.87  7.7  11.74\n  6.12  5.08  6.15 12.79  9.97  7.34  9.09 12.43  7.83  5.68  6.75  8.01\n  9.8  10.56  8.51  9.74  9.29  5.49  8.65  7.18  4.61 10.53 12.67  6.36\n  5.99  5.89  5.98  5.49  7.79  4.5   8.05  5.57 17.6  13.27 11.48 12.67\n  7.79 14.19 10.19 14.64  5.29  7.12 14.   13.33  3.26  3.73  2.96  9.53\n  8.88 34.77 37.97 13.44 23.24 21.24 23.69 21.78 17.21 21.08 23.6  24.56\n 30.63 30.81 28.28 31.99 30.62 20.85 17.11 18.76 25.68 15.17 16.35 17.12\n 19.37 19.92 30.59 29.97 26.77 20.32 20.31 19.77 27.38 22.98 23.34 12.13\n 26.4  19.78 10.11 21.22 34.37 20.08 36.98 29.05 25.79 26.64 20.62 22.74\n 15.02 15.7  14.1  23.29 17.16 24.39 15.69 14.52 21.52 24.08 17.64 19.69\n 12.03 16.22 15.17 23.27 18.05 26.45 34.02 22.88 22.11 19.52 16.59 18.85\n 23.79 23.98 17.79 16.44 18.13 19.31 17.44 17.73 17.27 16.74 18.71 18.13\n 19.01 16.94 16.23 14.7  16.42 14.65 13.99 10.29 13.22 14.13 17.15 21.32\n 18.13 14.76 16.29 12.87 14.36 11.66 18.14 24.1  18.68 24.91 18.03 13.11\n 10.74  7.74  7.01 10.42 13.34 10.58 14.98 11.45 18.06 23.97 29.68 18.07\n 13.35 12.01 13.59 17.6  21.14 14.1  12.92 15.1  14.33  9.67  9.08  5.64\n  6.48  7.88].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10932\\58874995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mregression_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Fit the data(train the model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mregression_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregression_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 4.98  9.14  4.03  2.94  5.33  5.21 12.43 19.15 29.93 17.1  20.45 13.27\n 15.71  8.26 10.26  8.47  6.58 14.67 11.69 11.28 21.02 13.83 18.72 19.88\n 16.3  16.51 14.81 17.28 12.8  11.98 22.6  13.04 27.71 18.35 20.34  9.68\n 11.41  8.77 10.13  4.32  1.98  4.84  5.81  7.44  9.55 10.21 14.15 18.8\n 30.81 16.2  13.45  9.43  5.28  8.43 14.8   4.81  5.77  3.95  6.86  9.22\n 13.15 14.44  6.73  9.5   8.05  4.67 10.24  8.1  13.09  8.79  6.72  9.88\n  5.52  7.54  6.78  8.94 11.97 10.27 12.34  9.1   5.29  7.22  6.72  7.51\n  9.62  6.53 12.86  8.44  5.5   5.7   8.81  8.2   8.16  6.21 10.59  6.65\n 11.34  4.21  3.57  6.19  9.42  7.67 10.63 13.44 12.33 16.47 18.66 14.09\n 12.27 15.55 13.   10.16 16.21 17.09 10.45 15.76 12.04 10.3  15.37 13.61\n 14.37 14.27 17.93 25.41 17.58 14.81 27.26 17.19 15.39 18.34 12.6  12.26\n 11.12 15.03 17.31 16.96 16.9  14.59 21.32 18.46 24.16 34.41 26.82 26.42\n 29.29 27.8  16.65 29.53 28.32 21.45 14.1  13.28 12.12 15.79 15.12 15.02\n 16.14  4.59  6.43  7.39  5.5   1.73  1.92  3.32 11.64  9.81  3.7  12.14\n 11.1  11.32 14.43 12.03 14.69  9.04  9.64  5.33 10.11  6.29  6.92  5.04\n  7.56  9.45  4.82  5.68 13.98 13.15  4.45  6.68  4.56  5.39  5.1   4.69\n  2.87  5.03  4.38  2.97  4.08  8.61  6.62  4.56  4.45  7.43  3.11  3.81\n  2.88 10.87 10.97 18.06 14.66 23.09 17.27 23.98 16.03  9.38 29.55  9.47\n 13.51  9.69 17.92 10.5   9.71 21.46  9.93  7.6   4.14  4.63  3.13  6.36\n  3.92  3.76 11.65  5.25  2.47  3.95  8.05 10.88  9.54  4.73  6.36  7.37\n 11.38 12.4  11.22  5.19 12.5  18.46  9.16 10.15  9.52  6.56  5.9   3.59\n  3.53  3.54  6.57  9.25  3.11  5.12  7.79  6.9   9.59  7.26  5.91 11.25\n  8.1  10.45 14.79  7.44  3.16 13.65 13.    6.59  7.73  6.58  3.53  2.98\n  6.05  4.16  7.19  4.85  3.76  4.59  3.01  3.16  7.85  8.23 12.93  7.14\n  7.6   9.51  3.33  3.56  4.7   8.58 10.4   6.27  7.39 15.84  4.97  4.74\n  6.07  9.5   8.67  4.86  6.93  8.93  6.47  7.53  4.54  9.97 12.64  5.98\n 11.72  7.9   9.28 11.5  18.33 15.94 10.36 12.73  7.2   6.87  7.7  11.74\n  6.12  5.08  6.15 12.79  9.97  7.34  9.09 12.43  7.83  5.68  6.75  8.01\n  9.8  10.56  8.51  9.74  9.29  5.49  8.65  7.18  4.61 10.53 12.67  6.36\n  5.99  5.89  5.98  5.49  7.79  4.5   8.05  5.57 17.6  13.27 11.48 12.67\n  7.79 14.19 10.19 14.64  5.29  7.12 14.   13.33  3.26  3.73  2.96  9.53\n  8.88 34.77 37.97 13.44 23.24 21.24 23.69 21.78 17.21 21.08 23.6  24.56\n 30.63 30.81 28.28 31.99 30.62 20.85 17.11 18.76 25.68 15.17 16.35 17.12\n 19.37 19.92 30.59 29.97 26.77 20.32 20.31 19.77 27.38 22.98 23.34 12.13\n 26.4  19.78 10.11 21.22 34.37 20.08 36.98 29.05 25.79 26.64 20.62 22.74\n 15.02 15.7  14.1  23.29 17.16 24.39 15.69 14.52 21.52 24.08 17.64 19.69\n 12.03 16.22 15.17 23.27 18.05 26.45 34.02 22.88 22.11 19.52 16.59 18.85\n 23.79 23.98 17.79 16.44 18.13 19.31 17.44 17.73 17.27 16.74 18.71 18.13\n 19.01 16.94 16.23 14.7  16.42 14.65 13.99 10.29 13.22 14.13 17.15 21.32\n 18.13 14.76 16.29 12.87 14.36 11.66 18.14 24.1  18.68 24.91 18.03 13.11\n 10.74  7.74  7.01 10.42 13.34 10.58 14.98 11.45 18.06 23.97 29.68 18.07\n 13.35 12.01 13.59 17.6  21.14 14.1  12.92 15.1  14.33  9.67  9.08  5.64\n  6.48  7.88].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "m = [[x2],[x4],[x7],[x9],[x13]]\n",
    "print(m)\n",
    "regression_model = LinearRegression()\n",
    "#Fit the data(train the model)\n",
    "regression_model.fit(x, y)\n",
    "#predict\n",
    "y_predicted = regression_model.predict(x)\n",
    "print(y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93489de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.58962896e+01  2.33924484e+01  2.94366821e+01  2.77949618e+01\n",
      "  2.90455807e+01  2.32184386e+01  2.07555905e+01  2.20073497e+01\n",
      "  1.73971944e+01  2.03122100e+01  2.34865351e+01  2.06517584e+01\n",
      "  1.96656890e+01  1.96423024e+01  2.04684717e+01  1.87226835e+01\n",
      "  1.93287125e+01  1.98081763e+01  1.33010156e+01  1.78694560e+01\n",
      "  1.62703760e+01  1.97834209e+01  2.13141476e+01  1.85953319e+01\n",
      "  1.94320726e+01  1.46796651e+01  1.80841930e+01  1.83494866e+01\n",
      "  2.38618073e+01  2.51551955e+01  1.69630521e+01  2.02459226e+01\n",
      "  1.59167315e+01  1.69075373e+01  1.74964460e+01  1.97365797e+01\n",
      "  1.85408775e+01  1.89746388e+01  1.98398538e+01  2.93607350e+01\n",
      "  3.28080332e+01  2.58029864e+01  2.09253949e+01  2.15229398e+01\n",
      "  2.02629235e+01  1.74316408e+01  1.82674063e+01  2.00332688e+01\n",
      "  1.50300855e+01  1.66254231e+01  2.06828492e+01  2.18670724e+01\n",
      "  2.51181091e+01  2.09955351e+01  2.33915354e+01  3.50126111e+01\n",
      "  2.76833400e+01  3.21462682e+01  2.21147299e+01  2.06547101e+01\n",
      "  1.90694712e+01  2.05456302e+01  2.48573121e+01  2.71604818e+01\n",
      "  2.91813892e+01  2.70506795e+01  2.30084675e+01  1.95379581e+01\n",
      "  1.72718536e+01  1.96103898e+01  2.29985420e+01  1.91748284e+01\n",
      "  2.03381447e+01  2.14625039e+01  2.22750413e+01  2.20638822e+01\n",
      "  2.18577497e+01  2.10462228e+01  2.16196398e+01  1.90537866e+01\n",
      "  2.73369863e+01  2.64392987e+01  2.39215985e+01  2.26899341e+01\n",
      "  2.31663395e+01  2.50517351e+01  2.01977233e+01  2.11422868e+01\n",
      "  2.83573088e+01  2.89174115e+01  2.35597683e+01  2.34954889e+01\n",
      "  2.54761896e+01  2.36507756e+01  2.39779360e+01  2.43627727e+01\n",
      "  2.14437169e+01  3.68796018e+01  3.47995708e+01  3.16319588e+01\n",
      "  2.61635102e+01  2.66037391e+01  1.59904878e+01  2.14257868e+01\n",
      "  2.16737223e+01  1.92181276e+01  1.91183478e+01  2.12844355e+01\n",
      "  2.41986584e+01  2.21172060e+01  2.18584709e+01  2.61031283e+01\n",
      "  1.96966980e+01  2.11487089e+01  2.23074697e+01  1.86258200e+01\n",
      "  2.17092187e+01  2.04891154e+01  1.80261649e+01  1.80860888e+01\n",
      "  1.92309809e+01  2.00486392e+01  1.97312090e+01  1.87285644e+01\n",
      "  1.91158194e+01  2.01101497e+01  1.65483503e+01  1.79556238e+01\n",
      "  2.39946510e+01  1.75862112e+01  2.41173985e+01  2.30750032e+01\n",
      "  2.31741424e+01  1.87993550e+01  1.53448509e+01  2.31215600e+01\n",
      "  1.96021232e+01  2.41071937e+01  1.92917215e+01  2.17683008e+01\n",
      "  2.17557294e+01  1.27092461e+01  1.98292646e+01  1.63220685e+01\n",
      "  1.17925131e+01  1.63889972e+01  1.22533467e+01  1.18366503e+01\n",
      "  1.31006126e+01  1.62836225e+01  2.09785715e+01  1.44814044e+01\n",
      "  1.53821534e+01  1.50596882e+01  2.38136453e+01  1.85358011e+01\n",
      "  7.46535316e+00  2.73137075e+01  2.00621230e+01  2.38730911e+01\n",
      "  2.51976171e+01  3.19439068e+01  3.88182428e+01  4.33757253e+01\n",
      "  1.92149653e+01  1.75897653e+01  3.53471494e+01  1.54718259e+01\n",
      "  2.07068190e+01  2.21195128e+01  1.69722879e+01  1.83278879e+01\n",
      "  1.69619247e+01  2.37033535e+01  1.91647648e+01  2.45612171e+01\n",
      "  2.03174891e+01  2.27830100e+01  2.71277511e+01  2.82383769e+01\n",
      "  3.45299377e+01  2.15583371e+01  2.96007713e+01  2.48843011e+01\n",
      "  1.70159352e+01  2.12883347e+01  3.49158320e+01  2.92203596e+01\n",
      "  2.70168446e+01  3.24012796e+01  2.97536921e+01  2.83320804e+01\n",
      "  3.18782636e+01  2.98854583e+01  2.79195049e+01  3.98847824e+01\n",
      "  3.49473957e+01  3.25022823e+01  3.47327254e+01  3.33174393e+01\n",
      "  3.43078036e+01  2.61608670e+01  3.78350436e+01  4.06960394e+01\n",
      "  4.20983066e+01  1.93022706e+01  2.26826833e+01  1.81914728e+01\n",
      "  2.42932617e+01  1.89327396e+01  2.37971150e+01  1.94107291e+01\n",
      "  2.25505507e+01  2.29317704e+01  1.43873926e+01  2.15641359e+01\n",
      "  2.33345050e+01  2.53275921e+01  2.39737736e+01  2.72125511e+01\n",
      "  3.18926230e+01  2.56203116e+01  3.12154117e+01  2.52559715e+01\n",
      "  3.82842764e+01  4.19013827e+01  3.64695744e+01  2.90630862e+01\n",
      "  3.33669698e+01  2.43202656e+01  1.96359015e+01  3.10838960e+01\n",
      "  3.87188528e+01  3.78632562e+01  2.92151880e+01  2.04454307e+01\n",
      "  2.90320525e+01  3.08977301e+01  2.51308822e+01  2.62378703e+01\n",
      "  2.87273688e+01  2.23613465e+01  2.38463927e+01  2.41736155e+01\n",
      "  1.70422099e+01  1.75287979e+01  2.15789875e+01  2.21980678e+01\n",
      "  2.38659155e+01  2.66024256e+01  2.48767150e+01  2.40325292e+01\n",
      "  2.81650226e+01  3.88816229e+01  2.50625154e+01  2.32518084e+01\n",
      "  3.68256582e+01  4.33397833e+01  3.21563669e+01  2.83939636e+01\n",
      "  3.12986591e+01  3.37376854e+01  4.07334721e+01  3.23151942e+01\n",
      "  3.12377511e+01  1.81065698e+01  2.95716853e+01  3.98454011e+01\n",
      "  3.32600052e+01  2.46699490e+01  1.99933183e+01  2.32726572e+01\n",
      "  2.57065735e+01  3.88144319e+01  3.27539185e+01  2.94793854e+01\n",
      "  3.65475967e+01  3.30895999e+01  2.65109251e+01  2.79236755e+01\n",
      "  3.57010570e+01  2.88785846e+01  3.79836984e+01  4.48991304e+01\n",
      "  3.39202322e+01  2.66371809e+01  2.48620367e+01  2.45701041e+01\n",
      "  2.54219420e+01  2.68406051e+01  3.18866265e+01  3.41930178e+01\n",
      "  3.00302627e+01  2.09412035e+01  1.99929311e+01  2.52934397e+01\n",
      "  2.41618098e+01  1.80978024e+01  2.59966105e+01  3.16681224e+01\n",
      "  3.07540202e+01  2.67545957e+01  2.57065128e+01  2.97800522e+01\n",
      "  3.20782839e+01  2.71961880e+01  3.37850959e+01  2.91826092e+01\n",
      "  2.53850769e+01  2.00771627e+01  1.10718242e+01  2.13745267e+01\n",
      "  2.05328319e+01  2.23464672e+01  2.47631321e+01  1.77963479e+01\n",
      "  1.93329331e+01  1.84120481e+01  2.32767259e+01  2.10612528e+01\n",
      "  2.35032150e+01  2.31014047e+01  2.03793837e+01  1.75680392e+01\n",
      "  2.33849250e+01  2.33230705e+01  2.24422604e+01  2.06019691e+01\n",
      "  1.85684444e+01  2.21357607e+01  2.03522182e+01  1.94822436e+01\n",
      "  2.13491082e+01  2.21333707e+01  2.20778850e+01  2.01381122e+01\n",
      "  1.89127908e+01  1.90092230e+01  2.04911459e+01  1.99142861e+01\n",
      "  1.97776706e+01  3.17689969e+01  2.39710210e+01  2.89016659e+01\n",
      "  3.00014274e+01  1.93537437e+01  1.79284590e+01  2.87552535e+01\n",
      "  2.93968346e+01  2.92486617e+01  2.58057043e+01  2.68369341e+01\n",
      "  2.17570474e+01  2.99894322e+01  2.10239586e+01  2.30593431e+01\n",
      "  2.57486451e+01  2.74750242e+01  2.53812386e+01  2.11714361e+01\n",
      "  2.30889179e+01  2.13838237e+01  1.49780648e+01  2.19189161e+01\n",
      "  4.58781080e+01 -2.57455756e-02  1.03113210e+01 -2.81702428e+00\n",
      "  1.18318645e+01  2.96040569e+01  3.26976676e+01  2.16523122e+01\n",
      "  2.25047566e+01  1.18450247e+01  5.67937161e+00  3.11646677e+01\n",
      "  2.50295202e+01  2.69869783e+01  2.36553404e+01  2.23195643e+01\n",
      "  2.83756011e+01  2.49592968e+01  1.68406404e+01  1.67198856e+01\n",
      "  4.87343089e+00  1.47847875e+01  9.75535948e+00  1.25434898e+01\n",
      "  1.10051310e+01  1.56429214e+01  1.81478830e+01  2.04478845e+01\n",
      "  1.27911730e+01  2.20855573e+01  1.96279833e+01  2.42151000e+01\n",
      "  2.38081574e+01  1.84384151e+01  1.61886556e+01  1.80160547e+01\n",
      "  2.04635801e+01  2.33269014e+01  2.33189166e+01  1.53176221e+01\n",
      "  1.52147457e+01  1.77678838e+01  5.04701406e+00  1.59484975e+01\n",
      "  1.55836389e+01  2.23346942e+01  9.39928890e+00  1.73737804e+01\n",
      "  9.17173370e-01  9.41790673e+00  1.41858470e+00  1.53480042e+01\n",
      "  1.80139411e+01  8.64530958e+00  1.12668190e+01  1.89859281e+01\n",
      "  2.19938894e+01  1.87654681e+01  1.52092443e+01  1.20772317e+01\n",
      "  7.77334921e+00  1.05532824e+01  1.04624800e+01  1.32812834e+01\n",
      "  1.50236659e+01  1.56767272e+01  1.59385345e+01  1.97805152e+01\n",
      "  1.68728671e+01  1.69946964e+01  1.51882413e+01  1.88037918e+01\n",
      "  1.55428346e+01  1.26482430e+01  1.23179981e+01  1.75327633e+01\n",
      "  1.89317884e+01  2.34954530e+01  2.22307939e+01  2.41627094e+01\n",
      "  1.56774138e+01  1.58942595e+01  2.13787529e+01  2.22878800e+01\n",
      "  2.19434530e+01  2.16472471e+01  1.71671141e+01  2.47293683e+01\n",
      "  2.25489683e+01  3.11264939e+01  1.71189396e+01  1.65348478e+01\n",
      "  1.11508316e+01  1.06328723e+01  1.98658129e+01  2.10322716e+01\n",
      "  2.27128725e+01  2.32995785e+01  2.29260208e+01  2.44177850e+01\n",
      "  2.20202288e+01  1.69214603e+01  1.11801821e+01  1.88964205e+01\n",
      "  1.90948206e+01  1.80573797e+01  2.16711286e+01  2.21216607e+01\n",
      "  2.37807837e+01  2.77663721e+01  1.47850254e+01  1.95605428e+01\n",
      "  2.43228717e+01  1.37783275e+01  2.15552393e+01  2.20299866e+01\n",
      "  2.22091971e+01  2.62170907e+01  2.87551164e+01  1.81469889e+01\n",
      "  1.85645700e+01  2.24837156e+01  2.10614856e+01  1.93424561e+01\n",
      "  1.60994489e+01  1.45921148e+01  1.14006709e+01  2.02260296e+01\n",
      "  2.03452338e+01  1.80822791e+01  1.98422083e+01  1.76313322e+01\n",
      "  1.54658371e+01  1.86968983e+01  2.05850430e+01  1.69437770e+01\n",
      "  2.06345935e+01  2.50712054e+01  2.14168152e+01  2.83156588e+01\n",
      "  2.67355535e+01  2.06575773e+01]\n"
     ]
    }
   ],
   "source": [
    "m = [[x2],[x4],[x7],[x9],[x13]]\n",
    "m = df.loc[:,[\"ZN\",\"CHAS\",'RM',\"DIS\",\"B\"]]\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(m,y)\n",
    "y_predicted = regression_model.predict(m)\n",
    "print(y_predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d9701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
